const Bin = @import("./bin.zig").Bin;
const Dependency = @import("./dependency.zig");
const Integrity = @import("./integrity.zig").Integrity;
const Resolution = @import("./resolution.zig").Resolution;
const Repository = @import("./repository.zig").Repository;

const Lockfile = @import("./lockfile.zig");
const LoadResult = Lockfile.LoadResult;

const bun = @import("bun");
const logger = bun.logger;
const strings = bun.strings;

const Semver = bun.Semver;
const ExternalString = Semver.ExternalString;
const String = Semver.String;

const JSAst = bun.ast;
const Expr = JSAst.Expr;

const DependencyID = bun.install.DependencyID;
const ExtractTarball = bun.install.ExtractTarball;
const PackageID = bun.install.PackageID;
const PackageManager = bun.install.PackageManager;
const invalid_package_id = bun.install.invalid_package_id;

const std = @import("std");
const Allocator = std.mem.Allocator;

const OOM = bun.OOM;
const glob = bun.glob;

const MigrateYarnLockfileError = OOM || error{
    YarnLockfileVersionTooOld,
    YarnLockfileUnsupportedVersion,
    InvalidYarnLockfile,
    YarnLockfileParseError,
    WorkspaceNameMissing,
    UnresolvableDependency,
    NonExistentWorkspaceDependency,
    InvalidPackageJson,
    MissingPackageVersion,
    DependencyLoop,
};

fn invalidYarnLockfile() error{InvalidYarnLockfile} {
    return error.InvalidYarnLockfile;
}

pub fn migrateYarnLockfile(
    lockfile: *Lockfile,
    manager: *PackageManager,
    allocator: std.mem.Allocator,
    log: *logger.Log,
    data: []const u8,
    dir: bun.FD,
) MigrateYarnLockfileError!LoadResult {
    _ = dir;

    lockfile.initEmpty(allocator);
    bun.install.initializeStore();
    bun.analytics.Features.yarn_migration += 1;

    const is_yarn_v1 = strings.hasPrefixComptime(data, "# yarn lockfile v1") or
        strings.hasPrefixComptime(data, "# THIS IS AN AUTOGENERATED FILE");

    if (!is_yarn_v1) {
        const trimmed = strings.trim(data, " \t\n\r");
        if (strings.hasPrefixComptime(trimmed, "{")) {
            try log.addError(null, logger.Loc.Empty, "Yarn v2+ (Berry) lockfiles are not yet supported");
            return error.YarnLockfileUnsupportedVersion;
        }

        try log.addError(null, logger.Loc.Empty, "Invalid yarn.lock format. Expected '# yarn lockfile v1' header");
        return error.YarnLockfileVersionTooOld;
    }

    const entries = try parseYarnV1Lockfile(data, allocator, log);
    bun.Output.prettyErrorln("DEBUG: Parsed {d} entries from yarn.lock", .{entries.items.len});
    defer {
        for (entries.items) |*entry| {
            entry.deinit(allocator);
        }
        entries.deinit();
    }

    const pkg_map, const workspace_pkgs_off, const workspace_pkgs_end = build: {
        var string_buf = lockfile.stringBuf();

        var pkg_map: bun.StringArrayHashMap(PackageID) = .init(allocator);

        try pkg_map.putNoClobber(bun.fs.FileSystem.instance.top_level_dir, 0);

        {
            var pkg_json_path: bun.AutoAbsPath = .initTopLevelDir();
            defer pkg_json_path.deinit();

            pkg_json_path.append("package.json");

            const root_pkg_json = manager.workspace_package_json_cache.getWithPath(allocator, log, pkg_json_path.slice(), .{}).unwrap() catch {
                return invalidYarnLockfile();
            };

            const root_json = root_pkg_json.root;

            var root_pkg: Lockfile.Package = .{};

            if (try root_json.getString(allocator, "name")) |name_info| {
                const name, _ = name_info;
                const name_hash = String.Builder.stringHash(name);
                root_pkg.name = try string_buf.appendWithHash(name, name_hash);
                root_pkg.name_hash = name_hash;
            }

            const root_deps_off, const root_deps_len = try parsePackageJsonDependencies(
                lockfile,
                manager,
                allocator,
                &root_json,
                &string_buf,
                log,
            );

            root_pkg.dependencies = .{ .off = root_deps_off, .len = root_deps_len };
            root_pkg.resolutions = .{ .off = root_deps_off, .len = root_deps_len };
            root_pkg.meta.id = 0;
            root_pkg.resolution = .init(.{ .root = {} });

            if (root_json.get("bin")) |bin_expr| {
                root_pkg.bin = try Bin.parseAppend(allocator, bin_expr, &string_buf, &lockfile.buffers.extern_strings);
            } else if (root_json.get("directories")) |directories_expr| {
                if (directories_expr.get("bin")) |bin_expr| {
                    root_pkg.bin = try Bin.parseAppendFromDirectories(allocator, bin_expr, &string_buf);
                }
            }

            try lockfile.packages.append(allocator, root_pkg);
            try lockfile.getOrPutID(0, root_pkg.name_hash);

            if (root_json.get("workspaces")) |workspaces_expr| {
                var workspace_patterns = std.ArrayList([]const u8).init(allocator);
                defer workspace_patterns.deinit();

                if (workspaces_expr.data == .e_array) {
                    for (workspaces_expr.data.e_array.slice()) |pattern_expr| {
                        if (pattern_expr.asString(allocator)) |pattern| {
                            try workspace_patterns.append(pattern);
                        }
                    }
                } else if (workspaces_expr.data == .e_object) {
                    if (workspaces_expr.get("packages")) |packages_expr| {
                        if (packages_expr.data == .e_array) {
                            for (packages_expr.data.e_array.slice()) |pattern_expr| {
                                if (pattern_expr.asString(allocator)) |pattern| {
                                    try workspace_patterns.append(pattern);
                                }
                            }
                        }
                    }
                }

                var arena = std.heap.ArenaAllocator.init(allocator);
                defer arena.deinit();

                const GlobWalker = glob.GlobWalker(null, glob.walk.SyscallAccessor, false);

                for (workspace_patterns.items) |user_pattern| {
                    defer _ = arena.reset(.retain_capacity);

                    const glob_pattern = if (user_pattern.len == 0) "package.json" else brk: {
                        const parts = [_][]const u8{ user_pattern, "package.json" };
                        break :brk bun.handleOom(arena.allocator().dupe(u8, bun.path.join(parts, .auto)));
                    };

                    var walker: GlobWalker = .{};
                    const cwd = bun.fs.FileSystem.instance.top_level_dir;
                    if ((try walker.initWithCwd(&arena, glob_pattern, cwd, false, false, false, false, true)).asErr()) |_| {
                        continue;
                    }
                    defer walker.deinit(false);

                    var iter: GlobWalker.Iterator = .{
                        .walker = &walker,
                    };
                    defer iter.deinit();
                    if ((try iter.init()).asErr()) |_| {
                        continue;
                    }

                    while (switch (try iter.next()) {
                        .result => |r| r,
                        .err => |_| null,
                    }) |matched_path| {
                        if (strings.eqlComptime(matched_path, "package.json")) continue;

                        const entry_dir = bun.path.dirname(matched_path, .auto);

                        var ws_pkg_json_path: bun.AutoAbsPath = .initTopLevelDir();
                        defer ws_pkg_json_path.deinit();

                        ws_pkg_json_path.append(matched_path);

                        const ws_pkg_json = manager.workspace_package_json_cache.getWithPath(allocator, log, ws_pkg_json_path.slice(), .{}).unwrap() catch continue;
                        const ws_json = ws_pkg_json.root;

                        const name, _ = try ws_json.getString(allocator, "name") orelse continue;
                        const name_hash = String.Builder.stringHash(name);

                        try lockfile.workspace_paths.put(allocator, name_hash, try string_buf.append(entry_dir));

                        if (try ws_json.getString(allocator, "version")) |version_info| {
                            const version, _ = version_info;
                            const version_str = try string_buf.append(version);
                            const parsed = Semver.Version.parse(version_str.sliced(string_buf.bytes.items));
                            if (parsed.valid) {
                                try lockfile.workspace_versions.put(allocator, name_hash, parsed.version.min());
                            }
                        }
                    }
                }
            }
        }

        const workspace_pkgs_off = lockfile.packages.len;

        for (lockfile.workspace_paths.values()) |workspace_path| {
            var ws_pkg_json_path: bun.AutoAbsPath = .initTopLevelDir();
            defer ws_pkg_json_path.deinit();

            ws_pkg_json_path.append(workspace_path.slice(string_buf.bytes.items));
            const abs_path = try allocator.dupe(u8, ws_pkg_json_path.slice());
            ws_pkg_json_path.append("package.json");

            const ws_pkg_json = manager.workspace_package_json_cache.getWithPath(allocator, log, ws_pkg_json_path.slice(), .{}).unwrap() catch continue;
            const ws_json = ws_pkg_json.root;

            const name, _ = try ws_json.getString(allocator, "name") orelse continue;
            const name_hash = String.Builder.stringHash(name);

            var pkg: Lockfile.Package = .{
                .name = try string_buf.appendWithHash(name, name_hash),
                .name_hash = name_hash,
                .resolution = .init(.{ .workspace = workspace_path }),
            };

            const deps_off, const deps_len = try parsePackageJsonDependencies(
                lockfile,
                manager,
                allocator,
                &ws_json,
                &string_buf,
                log,
            );

            pkg.dependencies = .{ .off = deps_off, .len = deps_len };
            pkg.resolutions = .{ .off = deps_off, .len = deps_len };

            if (ws_json.get("bin")) |bin_expr| {
                pkg.bin = try Bin.parseAppend(allocator, bin_expr, &string_buf, &lockfile.buffers.extern_strings);
            } else if (ws_json.get("directories")) |directories_expr| {
                if (directories_expr.get("bin")) |bin_expr| {
                    pkg.bin = try Bin.parseAppendFromDirectories(allocator, bin_expr, &string_buf);
                }
            }

            const pkg_id = try lockfile.appendPackageDedupe(&pkg, string_buf.bytes.items);

            const entry = try pkg_map.getOrPut(abs_path);
            if (entry.found_existing) {
                return invalidYarnLockfile();
            }

            entry.value_ptr.* = pkg_id;
        }

        const workspace_pkgs_end = lockfile.packages.len;

        bun.Output.prettyErrorln("DEBUG: Phase 3 - Processing {d} entries", .{entries.items.len});
        var added_count: usize = 0;
        var skipped_workspace: usize = 0;
        var skipped_empty: usize = 0;
        var skipped_other: usize = 0;
        for (entries.items) |entry| {
            if (entry.specs.items.len > 0) {
                bun.Output.prettyErrorln("DEBUG: Checking entry: '{s}'", .{entry.specs.items[0]});
            }
            if (entry.specs.items.len == 0 or entry.version.len == 0) {
                skipped_empty += 1;
                continue;
            }

            const first_spec = entry.specs.items[0];

            if (strings.eqlComptime(entry.version, "0.0.0-use.local") or
                strings.hasPrefixComptime(entry.resolved, "file:packages/") or
                strings.hasPrefixComptime(entry.resolved, "file:../"))
            {
                skipped_workspace += 1;
                continue;
            }

            const name = blk: {
                if (strings.containsComptime(first_spec, "@npm:")) {
                    if (strings.hasPrefixComptime(first_spec, "@")) {
                        if (strings.indexOfChar(first_spec, '@')) |first_at| {
                            const after_first_at = first_spec[first_at + 1 ..];
                            if (strings.indexOfChar(after_first_at, '@')) |second_at_in_substr| {
                                const second_at = first_at + 1 + second_at_in_substr;
                                if (strings.hasPrefixComptime(first_spec[second_at..], "@npm:")) {
                                    const after_npm = first_spec[second_at + 5 ..];
                                    const extracted = extractPackageName(after_npm);
                                    break :blk extracted;
                                }
                            }
                        }
                    } else {
                        if (strings.indexOfChar(first_spec, '@')) |at_pos| {
                            const after_at = first_spec[at_pos + 1 ..];
                            if (strings.hasPrefixComptime(after_at, "npm:")) {
                                const after_npm = first_spec[at_pos + 5 ..];
                                const extracted = extractPackageName(after_npm);
                                break :blk extracted;
                            }
                        }
                    }
                }
                break :blk extractPackageName(first_spec);
            };

            const name_hash = String.Builder.stringHash(name);
            const name_string = try string_buf.appendWithHash(name, name_hash);

            var res: Resolution = undefined;

            if (strings.hasPrefixComptime(entry.resolved, "https://") or
                strings.hasPrefixComptime(entry.resolved, "http://"))
            {
                if (isDefaultRegistry(entry.resolved)) {
                    const version_str = try string_buf.append(entry.version);
                    const parsed = Semver.Version.parse(version_str.sliced(string_buf.bytes.items));

                    if (!parsed.valid) {
                        continue;
                    }

                    const scope = manager.scopeForPackageName(name);
                    const url = try ExtractTarball.buildURL(
                        scope.url.href,
                        strings.StringOrTinyString.init(name_string.slice(string_buf.bytes.items)),
                        parsed.version.min(),
                        string_buf.bytes.items,
                    );

                    res = .init(.{ .npm = .{
                        .version = parsed.version.min(),
                        .url = try string_buf.append(url),
                    } });
                } else if (strings.hasSuffixComptime(entry.resolved, ".tgz") or
                    strings.hasSuffixComptime(entry.resolved, ".tar.gz"))
                {
                    res = .init(.{ .remote_tarball = try string_buf.append(entry.resolved) });
                } else {
                    continue;
                }
            } else if (Dependency.Version.Tag.infer(entry.resolved) == .git) {
                const repo = try Repository.parseAppendGit(entry.resolved, &string_buf);
                res = .init(.{ .git = repo });
            } else if (Dependency.Version.Tag.infer(entry.resolved) == .github) {
                const repo = try Repository.parseAppendGithub(entry.resolved, &string_buf);
                res = .init(.{ .github = repo });
            } else if (strings.hasPrefixComptime(entry.resolved, "file:")) {
                const path = strings.withoutPrefixComptime(entry.resolved, "file:");
                if (strings.hasSuffixComptime(path, ".tgz") or strings.hasSuffixComptime(path, ".tar.gz")) {
                    res = .init(.{ .local_tarball = try string_buf.append(path) });
                } else {
                    res = .init(.{ .folder = try string_buf.append(path) });
                }
            } else {
                skipped_other += 1;
                continue;
            }

            added_count += 1;
            var pkg: Lockfile.Package = .{
                .name = name_string,
                .name_hash = name_hash,
                .resolution = res.copy(),
            };

            if (entry.integrity.len > 0) {
                pkg.meta.integrity = Integrity.parse(entry.integrity);
            }

            const deps_off, const deps_len = try parseYarnDependencies(
                lockfile,
                allocator,
                &entry,
                &string_buf,
                log,
            );

            pkg.dependencies = .{ .off = deps_off, .len = deps_len };
            pkg.resolutions = .{ .off = deps_off, .len = deps_len };

            const pkg_id = try lockfile.appendPackageDedupe(&pkg, string_buf.bytes.items);

            var key_buf: [1024]u8 = undefined;
            for (entry.specs.items) |spec| {
                const key = std.fmt.bufPrint(&key_buf, "{s}", .{spec}) catch continue;
                const pkg_entry = try pkg_map.getOrPut(try allocator.dupe(u8, key));
                if (!pkg_entry.found_existing) {
                    pkg_entry.value_ptr.* = pkg_id;
                }
            }
        }

        bun.Output.prettyErrorln("DEBUG: Phase 3 complete - added={d}, skipped_empty={d}, skipped_workspace={d}, skipped_other={d}, total_packages={d}", .{ added_count, skipped_empty, skipped_workspace, skipped_other, lockfile.packages.len });

        break :build .{
            pkg_map,
            workspace_pkgs_off,
            workspace_pkgs_end,
        };
    };

    const string_buf = lockfile.buffers.string_bytes.items;

    var res_buf: std.ArrayList(u8) = .init(allocator);
    defer res_buf.deinit();

    try lockfile.buffers.resolutions.ensureTotalCapacityPrecise(allocator, lockfile.buffers.dependencies.items.len);
    lockfile.buffers.resolutions.expandToCapacity();
    @memset(lockfile.buffers.resolutions.items, invalid_package_id);

    const pkgs = lockfile.packages.slice();
    const pkg_deps = pkgs.items(.dependencies);

    {
        for (pkg_deps[0].begin()..pkg_deps[0].end()) |_dep_id| {
            const dep_id: DependencyID = @intCast(_dep_id);
            const dep = &lockfile.buffers.dependencies.items[dep_id];
            const dep_name = dep.name.slice(string_buf);
            const version_str = dep.version.literal.slice(string_buf);

            res_buf.clearRetainingCapacity();
            try res_buf.writer().print("{s}@{s}", .{ dep_name, version_str });

            const pkg_id = pkg_map.get(res_buf.items) orelse {
                continue;
            };

            lockfile.buffers.resolutions.items[dep_id] = pkg_id;
        }
    }

    for (workspace_pkgs_off..workspace_pkgs_end) |_pkg_id| {
        const pkg_id: PackageID = @intCast(_pkg_id);
        const deps = pkg_deps[pkg_id];

        for (deps.begin()..deps.end()) |_dep_id| {
            const dep_id: DependencyID = @intCast(_dep_id);
            const dep = &lockfile.buffers.dependencies.items[dep_id];
            const dep_name = dep.name.slice(string_buf);
            const version_str = dep.version.literal.slice(string_buf);

            res_buf.clearRetainingCapacity();
            try res_buf.writer().print("{s}@{s}", .{ dep_name, version_str });

            const res_pkg_id = pkg_map.get(res_buf.items) orelse {
                continue;
            };

            lockfile.buffers.resolutions.items[dep_id] = res_pkg_id;
        }
    }

    for (workspace_pkgs_end..lockfile.packages.len) |_pkg_id| {
        const pkg_id: PackageID = @intCast(_pkg_id);
        const deps = pkg_deps[pkg_id];

        for (deps.begin()..deps.end()) |_dep_id| {
            const dep_id: DependencyID = @intCast(_dep_id);
            const dep = &lockfile.buffers.dependencies.items[dep_id];
            const dep_name = dep.name.slice(string_buf);
            const version_str = dep.version.literal.slice(string_buf);

            res_buf.clearRetainingCapacity();
            try res_buf.writer().print("{s}@{s}", .{ dep_name, version_str });

            const res_pkg_id = pkg_map.get(res_buf.items) orelse {
                continue;
            };

            lockfile.buffers.resolutions.items[dep_id] = res_pkg_id;
        }
    }

    try lockfile.resolve(log);

    try lockfile.fetchNecessaryPackageMetadataAfterYarnOrPnpmMigration(manager, true);

    return .{
        .ok = .{
            .lockfile = lockfile,
            .loaded_from_binary_lockfile = false,
            .migrated = .yarn,
            .serializer_result = .{},
            .format = .text,
        },
    };
}

const YarnEntry = struct {
    specs: std.ArrayList([]const u8),
    version: []const u8,
    resolved: []const u8,
    integrity: []const u8 = "",
    dependencies: std.StringHashMap([]const u8),
    optional_dependencies: std.StringHashMap([]const u8),

    fn init(allocator: std.mem.Allocator) YarnEntry {
        return .{
            .specs = std.ArrayList([]const u8).init(allocator),
            .version = "",
            .resolved = "",
            .dependencies = std.StringHashMap([]const u8).init(allocator),
            .optional_dependencies = std.StringHashMap([]const u8).init(allocator),
        };
    }

    fn deinit(self: *YarnEntry, allocator: std.mem.Allocator) void {
        self.specs.deinit();
        self.dependencies.deinit();
        self.optional_dependencies.deinit();
        if (self.version.len > 0) {
            allocator.free(self.version);
        }
        if (self.resolved.len > 0) {
            allocator.free(self.resolved);
        }
        if (self.integrity.len > 0) {
            allocator.free(self.integrity);
        }
    }
};

fn parseYarnV1Lockfile(
    data: []const u8,
    allocator: std.mem.Allocator,
    log: *logger.Log,
) !std.ArrayList(YarnEntry) {
    var entries = std.ArrayList(YarnEntry).init(allocator);
    errdefer {
        for (entries.items) |*entry| {
            entry.deinit(allocator);
        }
        entries.deinit();
    }

    var current_entry_idx: ?usize = null;
    var current_dep_map: ?*std.StringHashMap([]const u8) = null;
    var lines = std.mem.splitScalar(u8, data, '\n');

    while (lines.next()) |line| {
        if (line.len == 0 or strings.hasPrefixComptime(line, "#")) continue;

        const indent = blk: {
            var count: usize = 0;
            for (line) |c| {
                if (c == ' ') {
                    count += 1;
                } else {
                    break;
                }
            }
            break :blk count;
        };

        const content = line[indent..];
        if (content.len == 0) continue;

        bun.Output.prettyErrorln("DEBUG: indent={d}, content='{s}'", .{ indent, content });

        switch (indent) {
            0 => {
                current_entry_idx = null;
                current_dep_map = null;

                if (!strings.hasSuffixComptime(content, ":")) {
                    try log.addErrorFmt(null, logger.Loc.Empty, allocator, "Invalid yarn.lock entry (missing colon): {s}", .{content});
                    return error.YarnLockfileParseError;
                }

                const specs_str = content[0 .. content.len - 1];
                var entry = YarnEntry.init(allocator);

                var spec_iter = std.mem.splitSequence(u8, specs_str, ", ");
                while (spec_iter.next()) |spec_raw| {
                    const spec = strings.trim(spec_raw, " \t\"");
                    const spec_copy = try allocator.dupe(u8, spec);
                    try entry.specs.append(spec_copy);
                }

                try entries.append(entry);
                current_entry_idx = entries.items.len - 1;
            },
            2 => {
                if (current_entry_idx == null) continue;

                bun.Output.prettyErrorln("DEBUG: Processing indent=2, content='{s}'", .{content});
                if (strings.indexOfChar(content, ' ')) |space_idx| {
                    const key = content[0..space_idx];
                    const value_raw = content[space_idx + 1 ..];
                    const value = strings.trim(value_raw, " \t\"");

                    bun.Output.prettyErrorln("DEBUG: Found space at {d}, key='{s}', value='{s}'", .{ space_idx, key, value });
                    var entry = &entries.items[current_entry_idx.?];
                    if (strings.eqlComptime(key, "version")) {
                        entry.version = try allocator.dupe(u8, value);
                        bun.Output.prettyErrorln("DEBUG: Set version to '{s}', entry.version='{s}'", .{ value, entry.version });
                    } else if (strings.eqlComptime(key, "resolved")) {
                        entry.resolved = try allocator.dupe(u8, value);
                    } else if (strings.eqlComptime(key, "integrity")) {
                        entry.integrity = try allocator.dupe(u8, value);
                    } else if (strings.eqlComptime(key, "dependencies")) {
                        current_dep_map = &entry.dependencies;
                    } else if (strings.eqlComptime(key, "optionalDependencies")) {
                        current_dep_map = &entry.optional_dependencies;
                    }
                } else if (strings.hasSuffixComptime(content, ":")) {
                    const key = content[0 .. content.len - 1];
                    bun.Output.prettyErrorln("DEBUG: Found colon suffix, key='{s}'", .{key});
                    var entry = &entries.items[current_entry_idx.?];
                    if (strings.eqlComptime(key, "dependencies")) {
                        current_dep_map = &entry.dependencies;
                    } else if (strings.eqlComptime(key, "optionalDependencies")) {
                        current_dep_map = &entry.optional_dependencies;
                    }
                }
            },
            4 => {
                if (current_dep_map) |dep_map| {
                    if (strings.indexOfChar(content, ' ')) |space_idx| {
                        const dep_name_raw = content[0..space_idx];
                        const dep_name = strings.trim(dep_name_raw, " \t\"");
                        const dep_version_raw = content[space_idx + 1 ..];
                        const dep_version = strings.trim(dep_version_raw, " \t\"");

                        const name_copy = try allocator.dupe(u8, dep_name);
                        errdefer allocator.free(name_copy);
                        const version_copy = try allocator.dupe(u8, dep_version);
                        errdefer allocator.free(version_copy);

                        try dep_map.put(name_copy, version_copy);
                    }
                }
            },
            else => {},
        }
    }

    return entries;
}

fn extractPackageName(spec: []const u8) []const u8 {
    const at_idx = if (strings.hasPrefixComptime(spec, "@"))
        strings.indexOfChar(spec[1..], '@')
    else
        strings.indexOfChar(spec, '@');

    if (at_idx) |idx| {
        if (strings.hasPrefixComptime(spec, "@")) {
            return spec[0 .. idx + 1];
        }
        return spec[0..idx];
    }

    return spec;
}

fn isDefaultRegistry(url: []const u8) bool {
    return strings.containsComptime(url, "registry.yarnpkg.com") or
        strings.containsComptime(url, "registry.npmjs.org");
}

fn parsePackageJsonDependencies(
    lockfile: *Lockfile,
    manager: *PackageManager,
    allocator: std.mem.Allocator,
    pkg_json: *const Expr,
    string_buf: *String.Buf,
    log: *logger.Log,
) !struct { u32, u32 } {
    const dependency_groups = [_]struct { []const u8, Dependency.Behavior }{
        .{ "dependencies", .{ .prod = true } },
        .{ "devDependencies", .{ .dev = true } },
        .{ "optionalDependencies", .{ .optional = true } },
        .{ "peerDependencies", .{ .peer = true } },
    };

    const off = lockfile.buffers.dependencies.items.len;

    for (dependency_groups) |group| {
        const group_name, const group_behavior = group;
        if (pkg_json.get(group_name)) |deps| {
            if (!deps.isObject()) continue;

            for (deps.data.e_object.properties.slice()) |prop| {
                const key = prop.key.?;
                const value = prop.value.?;

                const name_str = key.asString(allocator) orelse continue;
                const name_hash = String.Builder.stringHash(name_str);
                const name = try string_buf.appendExternalWithHash(name_str, name_hash);

                const version_str = value.asString(allocator) orelse continue;
                const version = try string_buf.append(version_str);
                const version_sliced = version.sliced(string_buf.bytes.items);

                const dep: Dependency = .{
                    .name = name.value,
                    .name_hash = name.hash,
                    .behavior = group_behavior,
                    .version = Dependency.parse(
                        allocator,
                        name.value,
                        name.hash,
                        version_sliced.slice,
                        &version_sliced,
                        log,
                        manager,
                    ) orelse continue,
                };

                try lockfile.buffers.dependencies.append(allocator, dep);
            }
        }
    }

    const end = lockfile.buffers.dependencies.items.len;

    std.sort.pdq(
        Dependency,
        lockfile.buffers.dependencies.items[off..],
        string_buf.bytes.items,
        Dependency.isLessThan,
    );

    return .{ @intCast(off), @intCast(end - off) };
}

fn parseYarnDependencies(
    lockfile: *Lockfile,
    allocator: std.mem.Allocator,
    entry: *const YarnEntry,
    string_buf: *String.Buf,
    log: *logger.Log,
) !struct { u32, u32 } {
    const off = lockfile.buffers.dependencies.items.len;

    var dep_iter = entry.dependencies.iterator();
    while (dep_iter.next()) |kv| {
        const name_str = kv.key_ptr.*;
        const version_str = kv.value_ptr.*;

        const name_hash = String.Builder.stringHash(name_str);
        const name = try string_buf.appendExternalWithHash(name_str, name_hash);

        const version = try string_buf.append(version_str);
        const version_sliced = version.sliced(string_buf.bytes.items);

        const dep: Dependency = .{
            .name = name.value,
            .name_hash = name.hash,
            .behavior = .{ .prod = true },
            .version = Dependency.parse(
                allocator,
                name.value,
                name.hash,
                version_sliced.slice,
                &version_sliced,
                log,
                null,
            ) orelse continue,
        };

        try lockfile.buffers.dependencies.append(allocator, dep);
    }

    var opt_dep_iter = entry.optional_dependencies.iterator();
    while (opt_dep_iter.next()) |kv| {
        const name_str = kv.key_ptr.*;
        const version_str = kv.value_ptr.*;

        const name_hash = String.Builder.stringHash(name_str);
        const name = try string_buf.appendExternalWithHash(name_str, name_hash);

        const version = try string_buf.append(version_str);
        const version_sliced = version.sliced(string_buf.bytes.items);

        const dep: Dependency = .{
            .name = name.value,
            .name_hash = name.hash,
            .behavior = .{ .optional = true },
            .version = Dependency.parse(
                allocator,
                name.value,
                name.hash,
                version_sliced.slice,
                &version_sliced,
                log,
                null,
            ) orelse continue,
        };

        try lockfile.buffers.dependencies.append(allocator, dep);
    }

    const end = lockfile.buffers.dependencies.items.len;

    std.sort.pdq(
        Dependency,
        lockfile.buffers.dependencies.items[off..],
        string_buf.bytes.items,
        Dependency.isLessThan,
    );

    return .{ @intCast(off), @intCast(end - off) };
}
